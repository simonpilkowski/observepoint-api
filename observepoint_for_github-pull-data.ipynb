{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ObservePoint API Management to Scale Governance for a large scale of Digital Assets \n",
    "## Pull data for exisiting ObservePoint Audits\n",
    "\n",
    "1. [Load Libraries](#1.-Load-Libraries-needed)\n",
    "1. [Setup](#2.-Setup-API-&-Database-Connection-&-Template-Audit-ID)\n",
    "1. [Initialize Database](#3.-Initialize-Database-Tables-if-not-exist)\n",
    "1. [API Call](#4.-API-Call)\n",
    "1. [API Call with retries](#5.-API-Call-retries-(to-prevent-timeouts))\n",
    "1. [Get all existing Audits](#6.-Get-all-existing-Audits)\n",
    "1. [Get all runs](#7.-Get-all-runs-(run-=-ObservePoint-crawl)-for-all-all-audits)\n",
    "1. [Get all Tags and Statistics for last run](#8.-Get-all-Tags-and-Statistics-for-last-run)\n",
    "1. [Get Status Codes for last Run](#9.-Get-Status-Codes-for-last-Run-for-all-Audits)\n",
    "1. [Get Page Load time for last Run](#10.-Get-Page-Load-time-for-last-Run-for-all-Audits)\n",
    "1. [Pull all required data](#11.-Pull-all-required-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load Libraries needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If those modules are not installed in your environment \n",
    "# !pip install requests pandas sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as req\n",
    "import pandas as pd\n",
    "import json\n",
    "import operator\n",
    "import time\n",
    "import random\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Setup API & Database Connection & Template Audit ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apiKey = \"API_KEY\"\n",
    "api = \"https://api.observepoint.com/v2/\"\n",
    "\n",
    "engine = create_engine('postgresql://login:password@host:port/database?')\n",
    "\n",
    "template_audit_id = TEMPLATE_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Initialize Database Tables if not exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inint_db(engine):\n",
    "    SQL = f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS observepoint_runs (\n",
    "        audit_id bigint,\n",
    "        audit_name text,\n",
    "        run_id bigint,\n",
    "        run_completed timestamp with time zone\n",
    "    );\n",
    "    \n",
    "    CREATE TABLE IF NOT EXISTS observepoint_tag_summaries (\n",
    "        \"auditRunId\" bigint,\n",
    "        \"positionMiddle\" bigint,\n",
    "        noncompliant bigint,\n",
    "        inflation double precision,\n",
    "        duplicates double precision,\n",
    "        tagged bigint,\n",
    "        variables bigint,\n",
    "        \"positionTop\" bigint,\n",
    "        multiples double precision,\n",
    "        \"tagDuplicates\" bigint,\n",
    "        id bigint,\n",
    "        implementation double precision,\n",
    "        missing bigint,\n",
    "        \"positionBottom\" bigint,\n",
    "        \"tagMultiples\" bigint,\n",
    "        accounts bigint,\n",
    "        tag_name text,\n",
    "        tag_category text,\n",
    "        audit_id bigint,\n",
    "        run_id bigint\n",
    "    );\n",
    "    \n",
    "    CREATE TABLE IF NOT EXISTS observepoint_status_codes (\n",
    "        audit_id bigint,\n",
    "        number_pages bigint,\n",
    "        run_id bigint,\n",
    "        \"0\" double precision,\n",
    "        \"200\" double precision,\n",
    "        \"301\" double precision,\n",
    "        \"302\" double precision,\n",
    "        \"303\" double precision,\n",
    "        \"401\" double precision,\n",
    "        \"403\" double precision,\n",
    "        \"404\" double precision,\n",
    "        \"500\" double precision,\n",
    "        \"503\" double precision,\n",
    "        \"520\" double precision,\n",
    "        \"100\" text,\n",
    "        \"101\" text,\n",
    "        \"102\" text,\n",
    "        \"103\" text,\n",
    "        \"201\" text,\n",
    "        \"202\" text,\n",
    "        \"203\" text,\n",
    "        \"204\" text,\n",
    "        \"205\" text,\n",
    "        \"206\" text,\n",
    "        \"207\" text,\n",
    "        \"208\" text,\n",
    "        \"226\" text,\n",
    "        \"300\" text,\n",
    "        \"304\" text,\n",
    "        \"305\" text,\n",
    "        \"306\" text,\n",
    "        \"307\" text,\n",
    "        \"308\" text,\n",
    "        \"400\" text,\n",
    "        \"402\" text,\n",
    "        \"405\" text,\n",
    "        \"406\" text,\n",
    "        \"407\" text,\n",
    "        \"408\" text,\n",
    "        \"409\" text,\n",
    "        \"410\" text,\n",
    "        \"411\" text,\n",
    "        \"412\" text,\n",
    "        \"413\" text,\n",
    "        \"414\" text,\n",
    "        \"415\" text,\n",
    "        \"416\" text,\n",
    "        \"417\" text,\n",
    "        \"421\" text,\n",
    "        \"422\" text,\n",
    "        \"423\" text,\n",
    "        \"424\" text,\n",
    "        \"425\" text,\n",
    "        \"426\" text,\n",
    "        \"427\" text,\n",
    "        \"428\" text,\n",
    "        \"429\" text,\n",
    "        \"430\" text,\n",
    "        \"431\" text,\n",
    "        \"451\" text,\n",
    "        \"501\" text,\n",
    "        \"502\" text,\n",
    "        \"504\" text,\n",
    "        \"505\" text,\n",
    "        \"506\" text,\n",
    "        \"507\" text,\n",
    "        \"508\" text,\n",
    "        \"509\" text,\n",
    "        \"510\" text,\n",
    "        \"511\" text\n",
    "    );\n",
    "    \n",
    "    CREATE TABLE IF NOT EXISTS observepoint_load_times (\n",
    "        number_pages bigint,\n",
    "        avg_load_time double precision,\n",
    "        \"0-3_s\" bigint,\n",
    "        \"3-6_s\" bigint,\n",
    "        \"6-10_s\" bigint,\n",
    "        \"10-20_s\" bigint,\n",
    "        \">20\" bigint,\n",
    "        audit_id bigint,\n",
    "        run_id bigint\n",
    "    );\n",
    "    \"\"\"\n",
    "    \n",
    "    engine.execute(SQL)\n",
    "    \n",
    "inint_db(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. API Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(endpoint,method=\"GET\",payload={}):\n",
    "    headers = { \n",
    "                'authorization': \"api_key \" + apiKey,\n",
    "                'accept': 'application/json'\n",
    "    }\n",
    "    \n",
    "    if method in [\"POST\", \"PUT\"]:\n",
    "        headers['Content-Type'] = 'application/json'\n",
    "        \n",
    "    response = req.request(method, api+endpoint, data=payload, headers=headers)   \n",
    "    status_code = response.status_code\n",
    "    \n",
    "    if method in [\"GET\",\"POST\"]:\n",
    "        response = response.json()\n",
    "\n",
    "    return response, status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. API Call retries (to prevent timeouts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_with_retries(endpoint, method=\"GET\", payload={}, retries=3, suppress_exceptions=True):\n",
    "    data = None\n",
    "    \n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            data = get_data(endpoint, method, payload)\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            if not suppress_exceptions:\n",
    "                print(f\"Got exception {e}\")\n",
    "            else:\n",
    "                print(\"B\", end=\"\")\n",
    "        time.sleep(random.randint(a=3, b=10))\n",
    "        \n",
    "    raise Exception(f\"Getting data failed {retries} times for endpoint:{endpoint}, method:{method}, payload:{payload}. Giving up!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Get all existing Audits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audits():\n",
    "    audits , _ = get_data_with_retries(\"web-audits\")\n",
    "    audits = [audit for audit in audits if audit['id'] != template_audit_id]\n",
    "    \n",
    "    return audits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Get all runs (run = ObservePoint crawl) for all all audits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_runs(audits):\n",
    "    df_runs = pd.DataFrame()\n",
    "\n",
    "    for audit in audits:\n",
    "        runs , _ = get_data_with_retries(\"web-audits/\"+str(audit[\"id\"])+\"/runs\")\n",
    "        completed_run_ids = [(int(run['id']), run['completed']) for run in runs if run['completed']]\n",
    "\n",
    "        df_temp = pd.DataFrame({\n",
    "            'audit_id': audit[\"id\"], \n",
    "            'audit_name': audit['name'],\n",
    "            'run_id': map(operator.itemgetter(0), completed_run_ids),\n",
    "            'run_completed': map(operator.itemgetter(1), completed_run_ids)\n",
    "        })\n",
    "        df_runs = df_runs.append(df_temp)\n",
    "\n",
    "    df_runs['run_id'] = df_runs.run_id.astype(\"int\")\n",
    "    df_runs['run_completed'] = pd.to_datetime(df_runs.run_completed)\n",
    "    \n",
    "    return df_runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Get all Tags and Statistics for last run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tag_summaries(df_runs):\n",
    "    SQL = f\"\"\"\n",
    "        SELECT * \n",
    "          FROM observepoint_runs\n",
    "         WHERE (audit_id, run_id) NOT IN (\n",
    "             SELECT DISTINCT audit_id, run_id FROM observepoint_tag_summaries\n",
    "         )\n",
    "    \"\"\"\n",
    "\n",
    "    df_missing_runs = pd.read_sql(SQL, engine)\n",
    "\n",
    "    df_tag_summaries = pd.DataFrame()\n",
    "\n",
    "    # for _, row in df_missing_runs.iterrows():\n",
    "    for _, row in df_runs.iterrows():\n",
    "        audit_id = row['audit_id']\n",
    "        run_id = row['run_id']\n",
    "\n",
    "        tag_summaries , _ = get_data_with_retries(f\"web-audits/{audit_id}/runs/{run_id}/results/tag-summaries\", suppress_exceptions=False)\n",
    "        for tag in tag_summaries:\n",
    "            tag[\"tag_name\"] = tag[\"tag\"][\"name\"]\n",
    "            tag[\"tag_category\"]  = tag[\"tag\"][\"category\"][\"name\"]\n",
    "            tag[\"audit_id\"] = audit_id\n",
    "            tag[\"run_id\"] = run_id\n",
    "            del(tag['tag']) # FIXME: SKIPPING\n",
    "            del(tag['pagesPerVersion']) # FIXME: SKIPPING\n",
    "\n",
    "\n",
    "        df_tag_summaries = df_tag_summaries.append(pd.DataFrame(tag_summaries))\n",
    "    \n",
    "    return df_tag_summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Get Status Codes for last Run for all Audits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "http_response_codes = [\n",
    "    '100', '101', '102', '103', '200', '201', '202', '203','204', '205', \n",
    "    '206', '207', '208', '226', '300', '301', '302', '303', '304', '305', \n",
    "    '306', '307', '308', '400', '401', '402', '403', '404', '405', '406', \n",
    "    '407', '408', '409', '410', '411', '412', '413', '414', '415', '416', \n",
    "    '417', '421', '422', '423', '424', '425', '426', '427', '428', '429', \n",
    "    '430', '431', '451', '500', '501', '502', '503', '504', '505', '506', \n",
    "    '507', '508', '509', '510', '511', '520'\n",
    "]\n",
    "\n",
    "def get_status_codes():\n",
    "    SQL = f\"\"\"\n",
    "        SELECT * \n",
    "          FROM observepoint_runs\n",
    "         WHERE (audit_id, run_id) NOT IN (\n",
    "             SELECT DISTINCT audit_id, run_id FROM observepoint_status_codes\n",
    "         )\n",
    "    \"\"\"\n",
    "\n",
    "    df_missing_runs = pd.read_sql(SQL, engine)\n",
    "\n",
    "    df_status_codes = pd.DataFrame()\n",
    "\n",
    "    for _, row in df_missing_runs.iterrows():\n",
    "        audit_id = row['audit_id']\n",
    "        run_id = row['run_id']\n",
    "\n",
    "        status_codes , _ = get_data_with_retries(f\"web-audits/{audit_id}/runs/{run_id}/results/page/status-codes\")\n",
    "\n",
    "        status_codes_dict = [{\n",
    "            \"number_pages\" : status_codes[\"totalPages\"]\n",
    "\n",
    "        }]\n",
    "\n",
    "        for code_element in status_codes[\"runPages\"][0][\"pages\"][0][\"statusCodes\"]:\n",
    "            code = code_element[\"code\"]\n",
    "            count = code_element[\"pageCount\"]\n",
    "            status_codes_dict[0][str(code)] = count\n",
    "            status_codes_dict[0]['audit_id'] = audit_id\n",
    "            status_codes_dict[0]['run_id'] = run_id\n",
    "\n",
    "        df_status_codes = df_status_codes.append(pd.DataFrame(status_codes_dict))\n",
    "\n",
    "    for http_code in http_response_codes:\n",
    "        if http_code not in df_status_codes.columns.to_list():\n",
    "            df_status_codes[http_code] = None\n",
    "            \n",
    "    return df_status_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Get Page Load time for last Run for all Audits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_load_times():\n",
    "    SQL = f\"\"\"\n",
    "        SELECT * \n",
    "          FROM observepoint_runs\n",
    "         WHERE (audit_id, run_id) NOT IN (\n",
    "             SELECT DISTINCT audit_id, run_id FROM observepoint_load_times\n",
    "         )\n",
    "    \"\"\"\n",
    "\n",
    "    df_missing_runs = pd.read_sql(SQL, engine)\n",
    "\n",
    "    df_load_time = pd.DataFrame()\n",
    "\n",
    "    for _, row in df_missing_runs.iterrows():\n",
    "        audit_id = row['audit_id']\n",
    "        run_id = row['run_id']\n",
    "\n",
    "        load_time , _ = get_data_with_retries(f\"web-audits/{audit_id}/runs/{run_id}/results/page/load-time\")\n",
    "\n",
    "        load_time_dict = [{\n",
    "            \"number_pages\" : load_time[\"runPages\"][0][\"pages\"][0][\"pageCount\"],\n",
    "            \"avg_load_time\" : round(load_time[\"runPages\"][0][\"pages\"][0][\"averageLoadTimeMillis\"] /1000,2)\n",
    "\n",
    "        }]\n",
    "        number_pages = load_time[\"runPages\"][0][\"pages\"][0][\"pageCount\"]\n",
    "        for item in load_time[\"runPages\"][0][\"pages\"][0][\"loadTimes\"]:\n",
    "            start = item[\"interval\"][\"start\"]\n",
    "            end = item[\"interval\"][\"end\"]\n",
    "            count = item[\"pageCount\"]\n",
    "\n",
    "            if end <= 20: \n",
    "                load_time_dict[0][\"\"+str(start)+\"-\"+str(end)+\"_s\"] = count\n",
    "            else:\n",
    "                load_time_dict[0][\">\"+str(start)] = count\n",
    "\n",
    "        load_time_dict[0]['audit_id'] = audit_id\n",
    "        load_time_dict[0]['run_id']   = run_id\n",
    "\n",
    "        avg_load_time = round(load_time[\"runPages\"][0][\"pages\"][0][\"averageLoadTimeMillis\"] /1000,2)\n",
    "\n",
    "\n",
    "        df_load_time = df_load_time.append(pd.DataFrame(load_time_dict))\n",
    "\n",
    "    return df_load_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Pull all required data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_observepoint(engine):\n",
    "    print(\"Before Audits\")\n",
    "    audits = get_audits()\n",
    "    print(\"After Audits\")\n",
    "        \n",
    "    print(\"Before Runs\")\n",
    "    df_runs = get_runs(audits)\n",
    "    engine.execute(\"TRUNCATE observepoint_runs\")\n",
    "    df_runs.to_sql(\"observepoint_runs\", engine, if_exists=\"append\", index=False)\n",
    "    print(\"After Runs\")\n",
    "   \n",
    "    print(\"Before Tag Summaries\")    \n",
    "    engine.execute(\"TRUNCATE observepoint_tag_summaries\")\n",
    "    df_tag_summaries = get_tag_summaries(df_runs)\n",
    "    df_tag_summaries.to_sql(\"observepoint_tag_summaries\", engine, if_exists=\"append\", index=False)\n",
    "    print(\"After Tag Summaries\")\n",
    "\n",
    "    print(\"Before Status Codes\")    \n",
    "    df_status_codes = get_status_codes()\n",
    "    engine.execute(\"TRUNCATE observepoint_status_codes\")    \n",
    "    df_status_codes.to_sql(\"observepoint_status_codes\", engine, if_exists=\"append\", index=False)\n",
    "    print(\"After Status Codes\")    \n",
    "\n",
    "    print(\"Before Load Times\")        \n",
    "    df_load_time = get_load_times()\n",
    "    engine.execute(\"TRUNCATE observepoint_load_times\")    \n",
    "    df_load_time.to_sql('observepoint_load_times', engine, if_exists=\"append\", index=False)\n",
    "    print(\"After Load Times\")    \n",
    "    \n",
    "process_observepoint(engine)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
